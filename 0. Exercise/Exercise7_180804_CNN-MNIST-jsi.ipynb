{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 11 MNIST and Deep Learning CNN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Detail info. about MNIST dataset: https://www.tensorflow.org/get_started/mnist/beginners\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate   = 0.001\n",
    "training_epochs = 15\n",
    "batch_size      = 100\n",
    "\n",
    "# dropout (keep_prob) rate 0.7 ~ 0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# input placeholders\n",
    "X     = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y     = tf.placeholder(tf.float32, [None, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"add_1:0\", shape=(?,10), dtype=float32)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L(Layer)1 ImgIn shape = (?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.01))\n",
    "#          Conv        -> (?, 28, 28, 32)\n",
    "#          Pool        -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1,keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\",      shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\",        shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\",     shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L(Layer)2 ImgIn shape = (?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#          Conv        -> (?, 14, 14, 64)\n",
    "#          Pool        -> (?, 7,  7,  64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\",      shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\",        shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\",     shape=(?, 7,  7,  64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7,  7,  64), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L(Layer)3 ImgIn shape = (?, 14, 14, 32)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#          Conv        -> (?, 7, 7, 128)\n",
    "#          Pool        -> (?, 4, 4, 128)\n",
    "#        Reshape       -> (?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\",      shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\",        shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\",     shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\",     shape=(?, 2048),      dtype=float32)\n",
    "'''\n",
    "\n",
    "# L(Layer)4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\",        shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L(Layer)5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?,10), dtype=float32)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-71b8589fa84b>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.360421116\n",
      "Epoch: 0002 cost = 0.099181929\n",
      "Epoch: 0003 cost = 0.073457020\n",
      "Epoch: 0004 cost = 0.059768335\n",
      "Epoch: 0005 cost = 0.050694524\n",
      "Epoch: 0006 cost = 0.045941656\n",
      "Epoch: 0007 cost = 0.039501624\n",
      "Epoch: 0008 cost = 0.039384845\n",
      "Epoch: 0009 cost = 0.035727270\n",
      "Epoch: 0010 cost = 0.032407477\n",
      "Epoch: 0011 cost = 0.030801878\n",
      "Epoch: 0012 cost = 0.029868400\n",
      "Epoch: 0013 cost = 0.027849227\n",
      "Epoch: 0014 cost = 0.028149875\n",
      "Epoch: 0015 cost = 0.026254823\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# Define cost/loss & Optimizer\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost    = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9927\n",
      "Label:       [2]\n",
      "Prediction:  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y,1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label:      \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28,28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
